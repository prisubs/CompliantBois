{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import datasets, svm\n",
    "'''\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X = X[y != 0, :2]\n",
    "y = y[y != 0]\n",
    "\n",
    "n_sample = len(X)\n",
    "\n",
    "np.random.seed(0)\n",
    "order = np.random.permutation(n_sample)\n",
    "X = X[order]\n",
    "y = y[order].astype(np.float)\n",
    "\n",
    "X_train = X[:int(.9 * n_sample)]\n",
    "y_train = y[:int(.9 * n_sample)]\n",
    "X_test = X[int(.9 * n_sample):]\n",
    "y_test = y[int(.9 * n_sample):]\n",
    "\n",
    "# fit the model\n",
    "for kernel in ('linear', 'rbf', 'poly'):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, cmap=plt.cm.Paired,\n",
    "                edgecolor='k', s=20)\n",
    "\n",
    "    # Circle out the test data\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], s=80, facecolors='none',\n",
    "                zorder=10, edgecolor='k')\n",
    "\n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'],\n",
    "                linestyles=['--', '-', '--'], levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.title(kernel)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP = []\n",
    "DOWN = []\n",
    "\n",
    "def count_words(original_string, bag_of_words):\n",
    "    split_string = original_string.lower().split()\n",
    "    count = 0\n",
    "    for word in bag_of_words:\n",
    "        matches = split_string.count(word)\n",
    "        count += matches\n",
    "    ratio = count/len(split_string)\n",
    "    return ratio\n",
    "    \n",
    "def aggregate_jsons(json_list):\n",
    "    result = []\n",
    "    for json in json_list:\n",
    "        headline = json[\"title\"]\n",
    "        desc = json[\"description\"]\n",
    "        x = headline + \" \" + desc\n",
    "        result.append(x)\n",
    "    return result\n",
    "\n",
    "def pipeline(df_path, ticky):\n",
    "    # get the dataframe from csv\n",
    "    df = pd.read_csv(df_path)\n",
    "    \n",
    "    # fix dates\n",
    "    df[\"Date\"] = df[\"Date\"].apply(lambda x: pd.to_datetime(x, infer_datetime_format=True))\n",
    "    df[\"Start\"] = df[\"Date\"].apply(str)\n",
    "    six_days = lambda start_date: start_date + datetime.timedelta(days=6)\n",
    "    df[\"End\"] = df[\"Date\"].apply(six_days).apply(str)\n",
    "    df = df.drop(columns=[\"Date\"])\n",
    "    remove_time = lambda dt: dt[0:10]\n",
    "    df[\"Start\"] = df[\"Start\"].apply(remove_time)\n",
    "    df[\"End\"] = df[\"End\"].apply(remove_time)\n",
    "    \n",
    "    # add json\n",
    "    client = TiingoClient({\"api_key\": \"a265fc4a1013923f970d16e7348195074e97fcb0\"})\n",
    "    query_ticker = lambda t, s, e: client.get_news(tickers=[t], startDate=s, endDate=e)\n",
    "    df[\"JSON\"] = df.apply(lambda d: query_ticker(ticky, d[\"Start\"], d[\"End\"]), axis=1)\n",
    "    \n",
    "    # create corpus\n",
    "    df[\"corpus\"] = df[\"JSON\"].apply(aggregate_jsons)\n",
    "    df[\"vectorized\"] = df[\"corpus\"]\n",
    "    combinatric = lambda l: ''.join(l)\n",
    "    df[\"corpus\"] = df[\"vectorized\"].apply(combinatric)\n",
    "    indicoio.config.api_key = \"25b83c4c388204edd2c6c11cd907e048\"\n",
    "    # add sentiment\n",
    "    df[\"sentiment\"] = df[\"corpus\"].apply(lambda orig: TextBlob(orig).sentiment.polarity)\n",
    "    df[\"sentiment_test\"] = df[\"vectorized\"].apply(lambda orig: [TextBlob(o).sentiment.polarity for o in orig]).apply(np.mean)\n",
    "    #df[\"indico_sentiment\"] = df[\"corpus\"].apply(lambda text: indicoio.sentiment_hq(text))\n",
    "    # add statistical features\n",
    "    # df[\"features\"] = df[\"corpus\"].apply(lambda text: indicoio.text_features(text, v=2))\n",
    "    \n",
    "    # add bag of words ratio\n",
    "    #df[\"bad_ratio\"] = \n",
    "    #df[\"good_keywords\"]\n",
    "    \n",
    "    # return the nice beautiful dataframe\n",
    "    df.to_csv('data/6m-weekly/aapl-6m-weekly.csv')\n",
    "    return df\n",
    "\n",
    "a = pipeline('data/6m-weekly/aapl-6m-weekly.csv', 'aapl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(d, ticky):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "def logistic_accuracy(y_pred, y_real):\n",
    "    y_pred, y_real = list(y_pred), list(y_real)\n",
    "    ct = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == y_real[i]:\n",
    "            ct += 1\n",
    "    return ct/len(y_pred)\n",
    "\n",
    "    \n",
    "def predictor_two(d, ticky):\n",
    "    import matplotlib.pyplot as plot\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn import utils\n",
    "    from sklearn import datasets, svm\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    d[\"lastweek\"] = d[\"Close\"]\n",
    "    d.lastweek = d.lastweek.shift(7) ## shift down\n",
    "    #df.lastweek.drop(df.gdp.shape[0] - 1,inplace = True) ## removing the first row\n",
    "    #X = np.c_[np.array(d[\"Open\"]), np.array(d[\"indico_sentiment\"])]\n",
    "    #print(d.head())\n",
    "    #X = impute(d[[\"sentiment\", \"indico_sentiment\"]])\n",
    "    #Y = d[\"Adj Close\"]\n",
    "    #Y = (Y - d[\"lastweek\"]) > 0\n",
    "    #y = Y\n",
    "    difs = d[\"Open\"] - d[\"Close\"]\n",
    "    y = pd.Series([1 if dif < 0 else 0 for dif in difs])\n",
    "    d[\"triangle\"] = y\n",
    "    #dataframe_xy = pd.DataFrame({'Open':d[\"Open\"], 'sentiment':d[\"sentiment\"], 'Y':Y})\n",
    "    Y = d[\"triangle\"]\n",
    "    #print(X)\n",
    "    #print(\"X length:\")\n",
    "    #print(X.size)\n",
    "    #print(Y)\n",
    "    #print(\"Y length:\")\n",
    "    #print(Y.size)\n",
    "    #scaler = MinMaxScaler()\n",
    "    #scaler.fit(d[\"Open\"])\n",
    "    #scaler.transform(d[\"Open\"])\n",
    "    d[\"Open\"] = d[\"Open\"] / d[\"Open\"].max()\n",
    "    d[\"lastweek\"] = d[\"lastweek\"] / d[\"lastweek\"].max()\n",
    "    #X = impute(d[[ \"lastweek\"]])\n",
    "    X = np.zeros((27, 2))\n",
    "    Y = d[\"triangle\"]\n",
    "    #print(X)\n",
    "    #print(Y)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 69)\n",
    "    # import some data to play with\n",
    "\n",
    "    clf = svm.SVC()\n",
    "\n",
    "    # Create an instance of Logistic Regression Classifier and fit the data.\n",
    "    #print(X_train)\n",
    "    #print(Y_train)\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    '''\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, cmap=plt.cm.Paired,\n",
    "                edgecolor='k', s=20)\n",
    "    '''\n",
    "\n",
    "    plt.axis('tight')\n",
    "    '''\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    print(X_train.shape[1])\n",
    "    print(X_test.shape[1])\n",
    "    '''\n",
    "    #print(\"X train!!!\")\n",
    "    #print(X_train)\n",
    "    #print(\"X test!\")\n",
    "    #print(X_test)\n",
    "    ''''\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z,\n",
    "                linestyles=['--', '-', '--'])\n",
    "\n",
    "    plt.title('linear')\n",
    "    '''\n",
    "    Y_predicted = clf.predict(X_test)\n",
    "    error_pct = logistic_accuracy(Y_predicted, Y_test)\n",
    "    print(\"****************** THIS IS THE ERROR PERCENT *******************\")\n",
    "    print(error_pct)\n",
    "    #plt.show()\n",
    "\n",
    "def impute(X):\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp = imp.fit(X)\n",
    "    X = imp.transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "#df = pipeline('data/6m-weekly/aapl-6m-weekly.csv', 'aapl')\n",
    "df = pd.read_csv('data/6m-weekly/aapl-6m-weekly.csv', error_bad_lines=False)\n",
    "predictor_two(df, 'aapl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
