{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tiingo import TiingoClient\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "import indicoio\n",
    "from textblob import TextBlob\n",
    "from sklearn import linear_model\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature functions\n",
    "def impute(X):\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp = imp.fit(X)\n",
    "    X = imp.transform(X)\n",
    "    return X\n",
    "\n",
    "def good_bag(string_vector):\n",
    "    bag = pd.read_csv(\"data/bag_of_words.csv\")\n",
    "    good_bag = bag[\"Good Words\"].apply(str.lower).to_list()\n",
    "    good_count = 0\n",
    "    for word in good_bag:\n",
    "        good_count += string_vector.count(word)\n",
    "    good = good_count / len(string_vector)\n",
    "    return good\n",
    "\n",
    "\n",
    "def bad_bag(string_vector):\n",
    "    bag = pd.read_csv(\"data/bag_of_words.csv\")\n",
    "    bad_bag = bag[\"Bad Words\"].apply(str.lower).to_list()\n",
    "    bad_count = 0\n",
    "    for word in bad_bag:\n",
    "        bad_count += string_vector.count(word)\n",
    "    bad = bad_count / len(string_vector)\n",
    "    return bad\n",
    "\n",
    "\n",
    "def aggregate_jsons(json_list):\n",
    "    result = []\n",
    "    for json in json_list:\n",
    "        headline = json[\"title\"]\n",
    "        desc = json[\"description\"]\n",
    "        x = headline + \" \" + desc\n",
    "        result.append(x)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df_path, ticky):\n",
    "    # get the dataframe from csv\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "    # fix dates\n",
    "    df[\"Date\"] = df[\"Date\"].apply(lambda x: pd.to_datetime(x, infer_datetime_format=True))\n",
    "    df[\"Start\"] = df[\"Date\"].apply(str)\n",
    "    six_days = lambda start_date: start_date + datetime.timedelta(days=6)\n",
    "    df[\"End\"] = df[\"Date\"].apply(six_days).apply(str)\n",
    "    df = df.drop(columns=[\"Date\"])\n",
    "    remove_time = lambda dt: dt[0:10]\n",
    "    df[\"Start\"] = df[\"Start\"].apply(remove_time)\n",
    "    df[\"End\"] = df[\"End\"].apply(remove_time)\n",
    "\n",
    "    # add json \n",
    "    client = TiingoClient({\"api_key\": \"a265fc4a1013923f970d16e7348195074e97fcb0\"})\n",
    "    query_ticker = lambda t, s, e: client.get_news(tickers=[t], startDate=s, endDate=e)\n",
    "    df[\"JSON\"] = df.apply(lambda d: query_ticker(ticky, d[\"Start\"], d[\"End\"]), axis=1)\n",
    "\n",
    "    # create corpus\n",
    "    df[\"corpus\"] = df[\"JSON\"].apply(aggregate_jsons)\n",
    "    df[\"vectorized\"] = df[\"corpus\"]\n",
    "    combinatric = lambda l: ''.join(l)\n",
    "    df[\"corpus\"] = df[\"vectorized\"].apply(combinatric)\n",
    "    \n",
    "    # new key 04878c9a5bb99aaf8a8ccdd65954442a under prianka@contrarycap.com\n",
    "    indicoio.config.api_key = \"04878c9a5bb99aaf8a8ccdd65954442a\"\n",
    "\n",
    "    # add sentiment\n",
    "    df[\"sentiment\"] = df[\"corpus\"].apply(lambda orig: TextBlob(orig).sentiment.polarity)\n",
    "    df[\"sentiment_test\"] = df[\"vectorized\"].apply(lambda orig: [TextBlob(o).sentiment.polarity for o in orig]).apply(\n",
    "        np.mean)\n",
    "    df[\"indico_sentiment\"] = df[\"corpus\"].apply(lambda text: indicoio.sentiment_hq(text))\n",
    "\n",
    "    # add bag of words featurization\n",
    "    df[\"bad_bag\"] = df[\"vectorized\"].apply(bad_bag)\n",
    "    df[\"good_bag\"] = df[\"vectorized\"].apply(good_bag)\n",
    "\n",
    "    # return the nice beautiful dataframe\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a BIG FAT dataframe\n",
    "# returns a trained Bayesian Ridge regression object that can be pickled\n",
    "def massive_lm(d):\n",
    "    d[\"lastweek\"] = d[\"Close\"]\n",
    "    d.lastweek = d.lastweek.shift(7)\n",
    "    training_X_cols = [\"Open\", \"lastweek\", \"indico_sentiment\", \"sentiment\", \"sentiment_test\", \"bad_bag\", \"good_bag\"]\n",
    "    training_Y_col = \"Close\"\n",
    "\n",
    "    # Train on ALL rows\n",
    "\n",
    "    X_train = impute(d[training_X_cols])\n",
    "    Y_train = d[training_Y_col]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    model = linear_model.BayesianRidge()\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"created bayesian ridge regression model. returning !\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a model object\n",
    "# writes it out to a PKL file\n",
    "def pickle_up(model, filepath):\n",
    "    # save the classifier\n",
    "    with open(filepath, 'wb') as fid:\n",
    "        cPickle.dump(model, fid) \n",
    "    print(\"saved model to {0}\".format(filepath))\n",
    "        \n",
    "def pickle_down(filepath):\n",
    "    # load it again\n",
    "    with open(filepath, 'rb') as fid:\n",
    "        model_loaded = cPickle.load(fid)\n",
    "    return model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"aapl\", \"amzn\", \"baba\", \"crm\", \"fb\", \"googl\", \"msft\", \"nflx\", \"tsla\", \"wmt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bois = []\n",
    "# prepare all rows into a giant train-ready dataset\n",
    "for ticker in tickers:\n",
    "    ticked_df = pipeline('data/6m-weekly/{0}-6m-weekly.csv'.format(ticker), ticker)\n",
    "    bois.append(ticked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(bois, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>JSON</th>\n",
       "      <th>corpus</th>\n",
       "      <th>vectorized</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_test</th>\n",
       "      <th>indico_sentiment</th>\n",
       "      <th>bad_bag</th>\n",
       "      <th>good_bag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148.149994</td>\n",
       "      <td>158.520004</td>\n",
       "      <td>146.589996</td>\n",
       "      <td>156.229996</td>\n",
       "      <td>154.966034</td>\n",
       "      <td>191160200</td>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>[{'crawlDate': '2019-04-10T14:13:54.677740Z', ...</td>\n",
       "      <td>Apple hires Jaunt XR founder, sparking fresh s...</td>\n",
       "      <td>[Apple hires Jaunt XR founder, sparking fresh ...</td>\n",
       "      <td>0.073553</td>\n",
       "      <td>0.058019</td>\n",
       "      <td>0.887193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158.529999</td>\n",
       "      <td>159.360001</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>148.259995</td>\n",
       "      <td>147.060516</td>\n",
       "      <td>221962500</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>[{'crawlDate': '2019-04-10T14:13:54.677740Z', ...</td>\n",
       "      <td>Apple hires Jaunt XR founder, sparking fresh s...</td>\n",
       "      <td>[Apple hires Jaunt XR founder, sparking fresh ...</td>\n",
       "      <td>0.073553</td>\n",
       "      <td>0.058019</td>\n",
       "      <td>0.887193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148.699997</td>\n",
       "      <td>154.529999</td>\n",
       "      <td>145.899994</td>\n",
       "      <td>152.289993</td>\n",
       "      <td>151.057922</td>\n",
       "      <td>203706100</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>[{'crawlDate': '2019-04-10T14:13:54.677740Z', ...</td>\n",
       "      <td>Apple hires Jaunt XR founder, sparking fresh s...</td>\n",
       "      <td>[Apple hires Jaunt XR founder, sparking fresh ...</td>\n",
       "      <td>0.073553</td>\n",
       "      <td>0.058019</td>\n",
       "      <td>0.887193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150.850006</td>\n",
       "      <td>157.880005</td>\n",
       "      <td>149.220001</td>\n",
       "      <td>156.820007</td>\n",
       "      <td>155.551285</td>\n",
       "      <td>155292000</td>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>[{'crawlDate': '2019-04-10T14:13:54.677740Z', ...</td>\n",
       "      <td>Apple hires Jaunt XR founder, sparking fresh s...</td>\n",
       "      <td>[Apple hires Jaunt XR founder, sparking fresh ...</td>\n",
       "      <td>0.073553</td>\n",
       "      <td>0.058019</td>\n",
       "      <td>0.887193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156.410004</td>\n",
       "      <td>158.130005</td>\n",
       "      <td>151.699997</td>\n",
       "      <td>157.759995</td>\n",
       "      <td>156.483673</td>\n",
       "      <td>112501600</td>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>[{'crawlDate': '2019-04-10T14:13:54.677740Z', ...</td>\n",
       "      <td>Apple hires Jaunt XR founder, sparking fresh s...</td>\n",
       "      <td>[Apple hires Jaunt XR founder, sparking fresh ...</td>\n",
       "      <td>0.073553</td>\n",
       "      <td>0.058019</td>\n",
       "      <td>0.887193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open        High         Low       Close   Adj Close     Volume  \\\n",
       "0  148.149994  158.520004  146.589996  156.229996  154.966034  191160200   \n",
       "1  158.529999  159.360001  142.000000  148.259995  147.060516  221962500   \n",
       "2  148.699997  154.529999  145.899994  152.289993  151.057922  203706100   \n",
       "3  150.850006  157.880005  149.220001  156.820007  155.551285  155292000   \n",
       "4  156.410004  158.130005  151.699997  157.759995  156.483673  112501600   \n",
       "\n",
       "        Start         End                                               JSON  \\\n",
       "0  2018-12-24  2018-12-30  [{'crawlDate': '2019-04-10T14:13:54.677740Z', ...   \n",
       "1  2018-12-31  2019-01-06  [{'crawlDate': '2019-04-10T14:13:54.677740Z', ...   \n",
       "2  2019-01-07  2019-01-13  [{'crawlDate': '2019-04-10T14:13:54.677740Z', ...   \n",
       "3  2019-01-14  2019-01-20  [{'crawlDate': '2019-04-10T14:13:54.677740Z', ...   \n",
       "4  2019-01-21  2019-01-27  [{'crawlDate': '2019-04-10T14:13:54.677740Z', ...   \n",
       "\n",
       "                                              corpus  \\\n",
       "0  Apple hires Jaunt XR founder, sparking fresh s...   \n",
       "1  Apple hires Jaunt XR founder, sparking fresh s...   \n",
       "2  Apple hires Jaunt XR founder, sparking fresh s...   \n",
       "3  Apple hires Jaunt XR founder, sparking fresh s...   \n",
       "4  Apple hires Jaunt XR founder, sparking fresh s...   \n",
       "\n",
       "                                          vectorized  sentiment  \\\n",
       "0  [Apple hires Jaunt XR founder, sparking fresh ...   0.073553   \n",
       "1  [Apple hires Jaunt XR founder, sparking fresh ...   0.073553   \n",
       "2  [Apple hires Jaunt XR founder, sparking fresh ...   0.073553   \n",
       "3  [Apple hires Jaunt XR founder, sparking fresh ...   0.073553   \n",
       "4  [Apple hires Jaunt XR founder, sparking fresh ...   0.073553   \n",
       "\n",
       "   sentiment_test  indico_sentiment  bad_bag  good_bag  \n",
       "0        0.058019          0.887193      0.0       0.0  \n",
       "1        0.058019          0.887193      0.0       0.0  \n",
       "2        0.058019          0.887193      0.0       0.0  \n",
       "3        0.058019          0.887193      0.0       0.0  \n",
       "4        0.058019          0.887193      0.0       0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created bayesian ridge regression model. returning !\n",
      "saved model to bayesian_model.pkl\n"
     ]
    }
   ],
   "source": [
    "model = massive_lm(df)\n",
    "pickle_up(model, \"bayesian_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
