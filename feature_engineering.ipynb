{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression bois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tiingo import TiingoClient\n",
    "from sklearn.impute import SimpleImputer\n",
    "import indicoio\n",
    "import seaborn as sns\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature vector creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_bag(string_vector):\n",
    "    bag = pd.read_csv(\"data/bag_of_words.csv\")\n",
    "    good_bag = bag[\"Good Words\"].apply(str.lower).to_list()\n",
    "    good_count = 0\n",
    "    for word in good_bag:\n",
    "        good_count += string_vector.count(word)\n",
    "    good = good_count/len(string_vector)\n",
    "    return good\n",
    "\n",
    "def bad_bag(string_vector):\n",
    "    bag = pd.read_csv(\"data/bag_of_words.csv\")\n",
    "    bad_bag = bag[\"Bad Words\"].apply(str.lower).to_list()\n",
    "    bad_count = 0\n",
    "    for word in bad_bag:\n",
    "        bad_count += string_vector.count(word)\n",
    "    bad = bad_count/len(string_vector)\n",
    "    return bad\n",
    "    \n",
    "def aggregate_jsons(json_list):\n",
    "    result = []\n",
    "    for json in json_list:\n",
    "        headline = json[\"title\"]\n",
    "        desc = json[\"description\"]\n",
    "        x = headline + \" \" + desc\n",
    "        result.append(x)\n",
    "    return result\n",
    "\n",
    "def pipeline(df_path, ticky):\n",
    "    # get the dataframe from csv\n",
    "    df = pd.read_csv(df_path)\n",
    "    \n",
    "    # fix dates\n",
    "    df[\"Date\"] = df[\"Date\"].apply(lambda x: pd.to_datetime(x, infer_datetime_format=True))\n",
    "    df[\"Start\"] = df[\"Date\"].apply(str)\n",
    "    six_days = lambda start_date: start_date + datetime.timedelta(days=6)\n",
    "    df[\"End\"] = df[\"Date\"].apply(six_days).apply(str)\n",
    "    df = df.drop(columns=[\"Date\"])\n",
    "    remove_time = lambda dt: dt[0:10]\n",
    "    df[\"Start\"] = df[\"Start\"].apply(remove_time)\n",
    "    df[\"End\"] = df[\"End\"].apply(remove_time)\n",
    "    \n",
    "    # add json\n",
    "    client = TiingoClient({\"api_key\": \"a265fc4a1013923f970d16e7348195074e97fcb0\"})\n",
    "    query_ticker = lambda t, s, e: client.get_news(tickers=[t], startDate=s, endDate=e)\n",
    "    df[\"JSON\"] = df.apply(lambda d: query_ticker(ticky, d[\"Start\"], d[\"End\"]), axis=1)\n",
    "    \n",
    "    # create corpus\n",
    "    df[\"corpus\"] = df[\"JSON\"].apply(aggregate_jsons)\n",
    "    df[\"vectorized\"] = df[\"corpus\"]\n",
    "    combinatric = lambda l: ''.join(l)\n",
    "    df[\"corpus\"] = df[\"vectorized\"].apply(combinatric)\n",
    "    indicoio.config.api_key = \"25b83c4c388204edd2c6c11cd907e048\"\n",
    "    \n",
    "    # add sentiment\n",
    "    df[\"sentiment\"] = df[\"corpus\"].apply(lambda orig: TextBlob(orig).sentiment.polarity)\n",
    "    df[\"sentiment_test\"] = df[\"vectorized\"].apply(lambda orig: [TextBlob(o).sentiment.polarity for o in orig]).apply(np.mean)\n",
    "    df[\"indico_sentiment\"] = df[\"corpus\"].apply(lambda text: indicoio.sentiment_hq(text))\n",
    "    \n",
    "    # add bag of words featurization\n",
    "    df[\"bad_bag\"] = df[\"vectorized\"].apply(bad_bag)\n",
    "    df[\"good_bag\"] = df[\"vectorized\"].apply(good_bag)\n",
    "    \n",
    "    # return the nice beautiful dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bayesian ridge regression\n",
    "predicting close price from open and other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(v1, v2):\n",
    "        return np.sum((v1 - v2) ** 2) \n",
    "\n",
    "def impute(X):\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp = imp.fit(X)\n",
    "    X = imp.transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(d, ticky):\n",
    "    d[\"lastweek\"] = d[\"Close\"]\n",
    "    df.lastweek = df.lastweek.shift(7) ## shift down\n",
    "    #df.lastweek.drop(df.gdp.shape[0] - 1,inplace = True) ## removing the first row\n",
    "    X = d[[\"Open\", \"lastweek\", \"indico_sentiment\", \"sentiment\", \"sentiment_test\", \"bad_bag\", \"good_bag\"]]\n",
    "    Y = d[\"Close\"]\n",
    "    \n",
    "    X = impute(X)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 69)\n",
    "    \n",
    "    model = linear_model.BayesianRidge()\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_predicted = model.predict(X_test)\n",
    "    error = mse(Y_predicted, Y_test)\n",
    "    print(\"aggregated error : {0}\".format(error))\n",
    "    print(\"average error by prediction for {1}: {0}\".format(np.mean(Y_predicted - Y_test), ticky))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ticker_linear(ticky):\n",
    "    print(\"******{0}*********\".format(ticky)*5)\n",
    "    start = time.time()\n",
    "    df = pipeline('data/6m-weekly/{0}-6m-weekly.csv'.format(ticky), ticky)\n",
    "    end = time.time()\n",
    "    pipeline_time = end - start\n",
    "    print(\"pipeline took {0}s for {1}\".format(pipeline_time, ticky))\n",
    "    imputer(df, ticky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['aapl', 'crm', 'tsla', 'fb', 'baba', 'msft', 'nflx', 'amzn', 'googl', 'wmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******aapl***************aapl***************aapl***************aapl***************aapl*********\n",
      "pipeline took 30.648231744766235s for aapl\n",
      "aggregated error : 1.449004747382989e-16\n",
      "average error by prediction for aapl: 3.7402969610411674e-10\n",
      "******crm***************crm***************crm***************crm***************crm*********\n",
      "pipeline took 30.65610694885254s for crm\n",
      "aggregated error : 8.08661352611945e-16\n",
      "average error by prediction for crm: 2.013820221691276e-09\n",
      "******tsla***************tsla***************tsla***************tsla***************tsla*********\n",
      "pipeline took 34.168715953826904s for tsla\n",
      "aggregated error : 2.661535321437689e-16\n",
      "average error by prediction for tsla: -3.6366335128453406e-09\n",
      "******fb***************fb***************fb***************fb***************fb*********\n",
      "pipeline took 30.925320386886597s for fb\n",
      "aggregated error : 1.6780559364645576e-16\n",
      "average error by prediction for fb: 1.6132572808500198e-09\n",
      "******baba***************baba***************baba***************baba***************baba*********\n",
      "pipeline took 33.72789192199707s for baba\n",
      "aggregated error : 4.082547197073833e-16\n",
      "average error by prediction for baba: -4.314102852731594e-09\n",
      "******msft***************msft***************msft***************msft***************msft*********\n",
      "pipeline took 39.31935691833496s for msft\n",
      "aggregated error : 2.1082729627653157e-16\n",
      "average error by prediction for msft: -5.798376100251011e-10\n",
      "******nflx***************nflx***************nflx***************nflx***************nflx*********\n",
      "pipeline took 31.996372938156128s for nflx\n",
      "aggregated error : 7.543924902365253e-17\n",
      "average error by prediction for nflx: -4.0662623885307564e-10\n",
      "******amzn***************amzn***************amzn***************amzn***************amzn*********\n",
      "pipeline took 31.6386981010437s for amzn\n",
      "aggregated error : 1.4351603273334578e-18\n",
      "average error by prediction for amzn: 7.326485097615255e-11\n",
      "******googl***************googl***************googl***************googl***************googl*********\n",
      "pipeline took 36.28045892715454s for googl\n",
      "aggregated error : 5.433963383786518e-17\n",
      "average error by prediction for googl: 1.3722253950416214e-09\n",
      "******wmt***************wmt***************wmt***************wmt***************wmt*********\n",
      "pipeline took 31.908727169036865s for wmt\n",
      "aggregated error : 1.801970593191128e-14\n",
      "average error by prediction for wmt: -1.0006593874499636e-08\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    run_ticker_linear(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression\n",
    "predicting whether it will be an up week or down week based on same features as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the up/down label\n",
    "# DOWN - 0\n",
    "# UP - 1\n",
    "\n",
    "def logistic_accuracy(y_pred, y_real):\n",
    "    y_pred, y_real = list(y_pred), list(y_real)\n",
    "    ct = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == y_real[i]:\n",
    "            ct += 1\n",
    "    return ct/len(y_pred)\n",
    "\n",
    "def add_updown(df):\n",
    "    difs = df[\"Open\"] - df[\"Close\"]\n",
    "    x = pd.Series([1 if dif < 0 else 0 for dif in difs])\n",
    "    df[\"triangle\"] = x\n",
    "    return df\n",
    "\n",
    "def prepare_logistic(path, ticky):\n",
    "    df = pipeline(path, ticky)\n",
    "    df = add_updown(df)\n",
    "    return df\n",
    "\n",
    "def logistic_reg(df, ticky):\n",
    "    X = impute(df[[\"indico_sentiment\", \"sentiment\", \"sentiment_test\", \"bad_bag\", \"good_bag\"]])\n",
    "    Y = df[\"triangle\"]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 69)\n",
    "    \n",
    "    model = linear_model.LogisticRegression(solver=\"lbfgs\")\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_predicted = model.predict(X_test)\n",
    "    \n",
    "    error_pct = logistic_accuracy(Y_predicted, Y_test)\n",
    "    return error_pct\n",
    "\n",
    "def run_logistic(ticker_list):\n",
    "    print(\"beginning logistic regression\")\n",
    "    for ticker in tickers:\n",
    "        print(\"******{0}*********\".format(ticker)*5)\n",
    "        filepath = 'data/6m-weekly/{0}-6m-weekly.csv'.format(ticker)\n",
    "        start = time.time()\n",
    "        df = prepare_logistic(filepath, ticker)\n",
    "        end = time.time()\n",
    "        pipeline_time = end - start\n",
    "        print(\"pipeline took {0}s for {1}\".format(pipeline_time, ticker))\n",
    "        accuracy_pct = logistic_reg(df, ticker) * 100\n",
    "        print(\"ticker: {0}\\naccuracy{1}%\".format(ticker, accuracy_pct))\n",
    "    print(\"finished logistic regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning logistic regression\n",
      "******aapl***************aapl***************aapl***************aapl***************aapl*********\n",
      "pipeline took 30.623436212539673s for aapl\n",
      "ticker: aapl\n",
      "accuracy71.42857142857143%\n",
      "******crm***************crm***************crm***************crm***************crm*********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 29.559911012649536s for crm\n",
      "ticker: crm\n",
      "accuracy42.857142857142854%\n",
      "******tsla***************tsla***************tsla***************tsla***************tsla*********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 33.41772508621216s for tsla\n",
      "ticker: tsla\n",
      "accuracy42.857142857142854%\n",
      "******fb***************fb***************fb***************fb***************fb*********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 29.98150086402893s for fb\n",
      "ticker: fb\n",
      "accuracy71.42857142857143%\n",
      "******baba***************baba***************baba***************baba***************baba*********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 35.60064387321472s for baba\n",
      "ticker: baba\n",
      "accuracy71.42857142857143%\n",
      "******msft***************msft***************msft***************msft***************msft*********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 37.82983589172363s for msft\n",
      "ticker: msft\n",
      "accuracy85.71428571428571%\n",
      "******nflx***************nflx***************nflx***************nflx***************nflx*********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 32.75851011276245s for nflx\n",
      "ticker: nflx\n",
      "accuracy71.42857142857143%\n",
      "******amzn***************amzn***************amzn***************amzn***************amzn*********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 33.28855013847351s for amzn\n",
      "ticker: amzn\n",
      "accuracy85.71428571428571%\n",
      "******googl***************googl***************googl***************googl***************googl*********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 32.60937714576721s for googl\n",
      "ticker: googl\n",
      "accuracy28.57142857142857%\n",
      "******wmt***************wmt***************wmt***************wmt***************wmt*********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 34.14972400665283s for wmt\n",
      "ticker: wmt\n",
      "accuracy71.42857142857143%\n",
      "finished logistic regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "run_logistic(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
