{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression bois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tiingo import TiingoClient\n",
    "from sklearn.impute import SimpleImputer\n",
    "import indicoio\n",
    "import seaborn as sns\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature vector creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_bag(string_vector):\n",
    "    bag = pd.read_csv(\"data/bag_of_words.csv\")\n",
    "    good_bag = bag[\"Good Words\"].apply(str.lower).to_list()\n",
    "    good_count = 0\n",
    "    for word in good_bag:\n",
    "        good_count += string_vector.count(word)\n",
    "    good = good_count/len(string_vector)\n",
    "    return good\n",
    "\n",
    "def bad_bag(string_vector):\n",
    "    bag = pd.read_csv(\"data/bag_of_words.csv\")\n",
    "    bad_bag = bag[\"Bad Words\"].apply(str.lower).to_list()\n",
    "    bad_count = 0\n",
    "    for word in bad_bag:\n",
    "        bad_count += string_vector.count(word)\n",
    "    bad = bad_count/len(string_vector)\n",
    "    return bad\n",
    "    \n",
    "def aggregate_jsons(json_list):\n",
    "    result = []\n",
    "    for json in json_list:\n",
    "        headline = json[\"title\"]\n",
    "        desc = json[\"description\"]\n",
    "        x = headline + \" \" + desc\n",
    "        result.append(x)\n",
    "    return result\n",
    "\n",
    "def pipeline(df_path, ticky):\n",
    "    # get the dataframe from csv\n",
    "    df = pd.read_csv(df_path)\n",
    "    \n",
    "    # fix dates\n",
    "    df[\"Date\"] = df[\"Date\"].apply(lambda x: pd.to_datetime(x, infer_datetime_format=True))\n",
    "    df[\"Start\"] = df[\"Date\"].apply(str)\n",
    "    six_days = lambda start_date: start_date + datetime.timedelta(days=6)\n",
    "    df[\"End\"] = df[\"Date\"].apply(six_days).apply(str)\n",
    "    df = df.drop(columns=[\"Date\"])\n",
    "    remove_time = lambda dt: dt[0:10]\n",
    "    df[\"Start\"] = df[\"Start\"].apply(remove_time)\n",
    "    df[\"End\"] = df[\"End\"].apply(remove_time)\n",
    "    \n",
    "    # add json\n",
    "    client = TiingoClient({\"api_key\": \"a265fc4a1013923f970d16e7348195074e97fcb0\"})\n",
    "    query_ticker = lambda t, s, e: client.get_news(tickers=[t], startDate=s, endDate=e)\n",
    "    df[\"JSON\"] = df.apply(lambda d: query_ticker(ticky, d[\"Start\"], d[\"End\"]), axis=1)\n",
    "    \n",
    "    # create corpus\n",
    "    df[\"corpus\"] = df[\"JSON\"].apply(aggregate_jsons)\n",
    "    df[\"vectorized\"] = df[\"corpus\"]\n",
    "    combinatric = lambda l: ''.join(l)\n",
    "    df[\"corpus\"] = df[\"vectorized\"].apply(combinatric)\n",
    "    indicoio.config.api_key = \"25b83c4c388204edd2c6c11cd907e048\"\n",
    "    \n",
    "    # add sentiment\n",
    "    df[\"sentiment\"] = df[\"corpus\"].apply(lambda orig: TextBlob(orig).sentiment.polarity)\n",
    "    df[\"sentiment_test\"] = df[\"vectorized\"].apply(lambda orig: [TextBlob(o).sentiment.polarity for o in orig]).apply(np.mean)\n",
    "    df[\"indico_sentiment\"] = df[\"corpus\"].apply(lambda text: indicoio.sentiment_hq(text))\n",
    "    \n",
    "    # add bag of words featurization\n",
    "    df[\"bad_bag\"] = df[\"vectorized\"].apply(bad_bag)\n",
    "    df[\"good_bag\"] = df[\"vectorized\"].apply(good_bag)\n",
    "    \n",
    "    # return the nice beautiful dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bayesian ridge regression\n",
    "predicting close price from open and other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(v1, v2):\n",
    "        return np.sum((v1 - v2) ** 2) \n",
    "\n",
    "def impute(X):\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp = imp.fit(X)\n",
    "    X = imp.transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(d, ticky):\n",
    "    d[\"lastweek\"] = d[\"Close\"]\n",
    "    d.lastweek = d.lastweek.shift(7) ## shift down\n",
    "    #df.lastweek.drop(df.gdp.shape[0] - 1,inplace = True) ## removing the first row\n",
    "    X = d[[\"Open\", \"lastweek\", \"indico_sentiment\", \"sentiment\", \"sentiment_test\", \"bad_bag\", \"good_bag\"]]\n",
    "    Y = d[\"Close\"]\n",
    "    \n",
    "    X = impute(X)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 100)\n",
    "    \n",
    "    model = linear_model.BayesianRidge()\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_predicted = model.predict(X_test)\n",
    "    error = mse(Y_predicted, Y_test)\n",
    "    print(\"aggregated error : {0}\".format(error))\n",
    "    print(\"average error by prediction for {1}: {0}\".format(np.mean(Y_predicted - Y_test), ticky))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ticker_linear(ticky):\n",
    "    print(\"******{0}*********\".format(ticky)*5)\n",
    "    start = time.time()\n",
    "    df = pipeline('data/6m-weekly/{0}-6m-weekly.csv'.format(ticky), ticky)\n",
    "    end = time.time()\n",
    "    pipeline_time = end - start\n",
    "    print(\"pipeline took {0}s for {1}\".format(pipeline_time, ticky))\n",
    "    imputer(df, ticky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['aapl', 'crm', 'tsla', 'fb', 'baba', 'msft', 'nflx', 'amzn', 'googl', 'wmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******aapl***************aapl***************aapl***************aapl***************aapl*********\n",
      "pipeline took 30.354820728302002s for aapl\n",
      "aggregated error : 502.3930738771067\n",
      "average error by prediction for aapl: -4.070810232309349\n",
      "******crm***************crm***************crm***************crm***************crm*********\n",
      "pipeline took 30.60937476158142s for crm\n",
      "aggregated error : 233.43297420304427\n",
      "average error by prediction for crm: -3.737919677218912\n",
      "******tsla***************tsla***************tsla***************tsla***************tsla*********\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for ticker in tickers:\n",
    "    run_ticker_linear(ticker)\n",
    "end = time.time()\n",
    "print(\"process took {} minutes\".format((end-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression\n",
    "predicting whether it will be an up week or down week based on same features as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the up/down label\n",
    "# DOWN - 0\n",
    "# UP - 1\n",
    "\n",
    "def logistic_accuracy(y_pred, y_real):\n",
    "    y_pred, y_real = list(y_pred), list(y_real)\n",
    "    ct = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == y_real[i]:\n",
    "            ct += 1\n",
    "    return ct/len(y_pred)\n",
    "\n",
    "def add_updown(df):\n",
    "    difs = df[\"Open\"] - df[\"Close\"]\n",
    "    x = pd.Series([1 if dif < 0 else 0 for dif in difs])\n",
    "    df[\"triangle\"] = x\n",
    "    return df\n",
    "\n",
    "def prepare_logistic(path, ticky):\n",
    "    df = pipeline(path, ticky)\n",
    "    df = add_updown(df)\n",
    "    return df\n",
    "\n",
    "def logistic_reg(df, ticky):\n",
    "    X = impute(df[[\"indico_sentiment\", \"sentiment\", \"sentiment_test\", \"bad_bag\", \"good_bag\"]])\n",
    "    Y = df[\"triangle\"]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 100)\n",
    "    \n",
    "    model = linear_model.LogisticRegression(solver=\"lbfgs\")\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_predicted = model.predict(X_test)\n",
    "    \n",
    "    error_pct = logistic_accuracy(Y_predicted, Y_test)\n",
    "    return error_pct\n",
    "\n",
    "def run_logistic(ticker_list):\n",
    "    print(\"beginning logistic regression\")\n",
    "    for ticker in tickers:\n",
    "        print(\"******{0}*********\".format(ticker)*5)\n",
    "        filepath = 'data/6m-weekly/{0}-6m-weekly.csv'.format(ticker)\n",
    "        start = time.time()\n",
    "        df = prepare_logistic(filepath, ticker)\n",
    "        end = time.time()\n",
    "        pipeline_time = end - start\n",
    "        print(\"pipeline took {0}s for {1}\".format(pipeline_time, ticker))\n",
    "        accuracy_pct = logistic_reg(df, ticker) * 100\n",
    "        print(\"ticker: {0}\\naccuracy{1}%\".format(ticker, accuracy_pct))\n",
    "    print(\"finished logistic regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logistic(tickers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
