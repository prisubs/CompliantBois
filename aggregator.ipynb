{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tiingo import TiingoClient\n",
    "import indicoio\n",
    "import seaborn as sns\n",
    "import time\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP = []\n",
    "DOWN = []\n",
    "\n",
    "def count_words(original_string, bag_of_words):\n",
    "    split_string = original_string.lower().split()\n",
    "    count = 0\n",
    "    for word in bag_of_words:\n",
    "        matches = split_string.count(word)\n",
    "        count += matches\n",
    "    ratio = count/len(split_string)\n",
    "    return ratio\n",
    "    \n",
    "def aggregate_jsons(json_list):\n",
    "    result = []\n",
    "    for json in json_list:\n",
    "        headline = json[\"title\"]\n",
    "        desc = json[\"description\"]\n",
    "        x = headline + \" \" + desc\n",
    "        result.append(x)\n",
    "    return result\n",
    "\n",
    "def pipeline(df_path, ticky):\n",
    "    # get the dataframe from csv\n",
    "    df = pd.read_csv(df_path)\n",
    "    \n",
    "    # fix dates\n",
    "    df[\"Date\"] = df[\"Date\"].apply(lambda x: pd.to_datetime(x, infer_datetime_format=True))\n",
    "    df[\"Start\"] = df[\"Date\"].apply(str)\n",
    "    six_days = lambda start_date: start_date + datetime.timedelta(days=6)\n",
    "    df[\"End\"] = df[\"Date\"].apply(six_days).apply(str)\n",
    "    df = df.drop(columns=[\"Date\"])\n",
    "    remove_time = lambda dt: dt[0:10]\n",
    "    df[\"Start\"] = df[\"Start\"].apply(remove_time)\n",
    "    df[\"End\"] = df[\"End\"].apply(remove_time)\n",
    "    \n",
    "    # add json\n",
    "    client = TiingoClient({\"api_key\": \"a265fc4a1013923f970d16e7348195074e97fcb0\"})\n",
    "    query_ticker = lambda t, s, e: client.get_news(tickers=[t], startDate=s, endDate=e)\n",
    "    df[\"JSON\"] = df.apply(lambda d: query_ticker(ticky, d[\"Start\"], d[\"End\"]), axis=1)\n",
    "    \n",
    "    # create corpus\n",
    "    df[\"corpus\"] = df[\"JSON\"].apply(aggregate_jsons)\n",
    "    df[\"vectorized\"] = df[\"corpus\"]\n",
    "    combinatric = lambda l: ''.join(l)\n",
    "    df[\"corpus\"] = df[\"vectorized\"].apply(combinatric)\n",
    "    \n",
    "    # add sentiment\n",
    "    df[\"sentiment\"] = df[\"corpus\"].apply(lambda orig: TextBlob(orig).sentiment.polarity)\n",
    "    df[\"sentiment_test\"] = df[\"corpus\"].apply(lambda orig: [TextBlob(o).sentiment.polarity for o in orig]).apply(np.mean)\n",
    "\n",
    "    # add statistical features\n",
    "    # df[\"features\"] = df[\"corpus\"].apply(lambda text: indicoio.text_features(text, v=2))\n",
    "    \n",
    "    # add bag of words ratio\n",
    "    #df[\"bad_ratio\"] = \n",
    "    #df[\"good_keywords\"]\n",
    "    \n",
    "    # return the nice beautiful dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = time.time()\n",
    "d = pipeline(\"TSLA-daily.csv\", \"tsla\")\n",
    "x = time.time()\n",
    "print(\"Function took {0}s to run\".format(x-g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(d[\"sentiment\"], d[\"Volume\"])\n",
    "sns.lineplot(d[\"sentiment_test\"], d[\"Volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = time.time()\n",
    "d = pipeline(\"MSFT-daily.csv\", \"msft\")\n",
    "x = time.time()\n",
    "print(\"Function took {0}s to run\".format(x-g))\n",
    "sns.lineplot(d[\"sentiment\"], d[\"Volume\"])\n",
    "sns.lineplot(d[\"sentiment_test\"], d[\"Volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = time.time()\n",
    "d = pipeline(\"AAPL-daily.csv\", \"aapl\")\n",
    "x = time.time()\n",
    "print(\"Function took {0}s to run\".format(x-g))\n",
    "sns.lineplot(d[\"sentiment\"], d[\"Volume\"])\n",
    "sns.lineplot(d[\"sentiment_test\"], d[\"Volume\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
