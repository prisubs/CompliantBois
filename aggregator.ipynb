{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tiingo import TiingoClient\n",
    "import indicoio\n",
    "import seaborn as sns\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP = []\n",
    "DOWN = []\n",
    "\n",
    "def count_words(original_string, bag_of_words):\n",
    "    split_string = original_string.lower().split()\n",
    "    count = 0\n",
    "    for word in bag_of_words:\n",
    "        matches = split_string.count(word)\n",
    "        count += matches\n",
    "    ratio = count/len(split_string)\n",
    "    return ratio\n",
    "    \n",
    "def aggregate_jsons(json_list):\n",
    "    result = []\n",
    "    for json in json_list:\n",
    "        headline = json[\"title\"]\n",
    "        desc = json[\"description\"]\n",
    "        x = headline + \" \" + desc\n",
    "        result.append(x)\n",
    "    return result\n",
    "\n",
    "def pipeline(df_path, ticky):\n",
    "    # get the dataframe from csv\n",
    "    df = pd.read_csv(df_path)\n",
    "    \n",
    "    # fix dates\n",
    "    df[\"Date\"] = df[\"Date\"].apply(lambda x: pd.to_datetime(x, infer_datetime_format=True))\n",
    "    df[\"Start\"] = df[\"Date\"].apply(str)\n",
    "    six_days = lambda start_date: start_date + datetime.timedelta(days=6)\n",
    "    df[\"End\"] = df[\"Date\"].apply(six_days).apply(str)\n",
    "    df = df.drop(columns=[\"Date\"])\n",
    "    remove_time = lambda dt: dt[0:10]\n",
    "    df[\"Start\"] = df[\"Start\"].apply(remove_time)\n",
    "    df[\"End\"] = df[\"End\"].apply(remove_time)\n",
    "    \n",
    "    # add json\n",
    "    client = TiingoClient({\"api_key\": \"a265fc4a1013923f970d16e7348195074e97fcb0\"})\n",
    "    query_ticker = lambda t, s, e: client.get_news(tickers=[t], startDate=s, endDate=e)\n",
    "    df[\"JSON\"] = df.apply(lambda d: query_ticker(ticky, d[\"Start\"], d[\"End\"]), axis=1)\n",
    "    \n",
    "    # create corpus\n",
    "    df[\"corpus\"] = df[\"JSON\"].apply(aggregate_jsons)\n",
    "    df[\"vectorized\"] = df[\"corpus\"]\n",
    "    combinatric = lambda l: ''.join(l)\n",
    "    df[\"corpus\"] = df[\"vectorized\"].apply(combinatric)\n",
    "    \n",
    "    # add sentiment\n",
    "    df[\"sentiment\"] = df[\"corpus\"].apply(lambda orig: TextBlob(orig).sentiment.polarity)\n",
    "    df[\"sentiment_test\"] = df[\"vectorized\"].apply(lambda orig: [TextBlob(o).sentiment.polarity for o in orig]).apply(np.mean)\n",
    "\n",
    "    # add statistical features\n",
    "    # df[\"features\"] = df[\"corpus\"].apply(lambda text: indicoio.text_features(text, v=2))\n",
    "    \n",
    "    # add bag of words ratio\n",
    "    #df[\"bad_ratio\"] = \n",
    "    #df[\"good_keywords\"]\n",
    "    \n",
    "    # return the nice beautiful dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(d, ticky):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import linear_model\n",
    "\n",
    "    d[\"constvec\"] = [0.7] * len(d)\n",
    "    X = d[[ \"constvec\", \"Open\"]]\n",
    "    Y = d[\"Close\"]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 69)\n",
    "\n",
    "    def mse(v1, v2):\n",
    "        return np.sum((v1 - v2) ** 2) \n",
    "    \n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_predicted = model.predict(X_test)\n",
    "    error = mse(Y_predicted, Y_test)\n",
    "    print(\"aggregated error : {0}\".format(error))\n",
    "    print(\"average error by prediction for {1}: {0}\".format(np.mean(Y_predicted - Y_test), ticky))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 11.742825031280518s for aapl\n",
      "aggregated error : 159.54332461455385\n",
      "average error by prediction for aapl: 0.44542909186680885\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pipeline('aapl-6m-weekly.csv', 'aapl')\n",
    "end = time.time()\n",
    "pipeline_time = end - start\n",
    "print(\"pipeline took {0}s for {1}\".format(pipeline_time, 'aapl'))\n",
    "predictor(df, 'aapl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 11.053886890411377s for crm\n",
      "aggregated error : 117.66546064007927\n",
      "average error by prediction for crm: 1.9394507607255618\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pipeline('crm-6m-weekly.csv', 'crm')\n",
    "end = time.time()\n",
    "pipeline_time = end - start\n",
    "print(\"pipeline took {0}s for {1}\".format(pipeline_time, 'crm'))\n",
    "predictor(df, 'crm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 11.279801845550537s for tsla\n",
      "aggregated error : 2973.1671609501473\n",
      "average error by prediction for tsla: -11.812941524549156\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pipeline('tsla-6m-weekly.csv', 'tsla')\n",
    "end = time.time()\n",
    "pipeline_time = end - start\n",
    "print(\"pipeline took {0}s for {1}\".format(pipeline_time, 'tsla'))\n",
    "predictor(df, 'tsla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 10.868243932723999s for fb\n",
      "aggregated error : 156.56163627135112\n",
      "average error by prediction for fb: 1.2611638446461138\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pipeline('fb-6m-weekly.csv', 'fb')\n",
    "end = time.time()\n",
    "pipeline_time = end - start\n",
    "print(\"pipeline took {0}s for {1}\".format(pipeline_time, 'fb'))\n",
    "predictor(df, 'fb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 14.068410158157349s for baba\n",
      "aggregated error : 346.613787113873\n",
      "average error by prediction for baba: -3.175124251872477\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pipeline('baba-6m-weekly.csv', 'baba')\n",
    "end = time.time()\n",
    "pipeline_time = end - start\n",
    "print(\"pipeline took {0}s for {1}\".format(pipeline_time, 'baba'))\n",
    "predictor(df, 'baba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 11.378664016723633s for msft\n",
      "aggregated error : 48.33394499831884\n",
      "average error by prediction for msft: 0.8648414383188623\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pipeline('msft-6m-weekly.csv', 'msft')\n",
    "end = time.time()\n",
    "pipeline_time = end - start\n",
    "print(\"pipeline took {0}s for {1}\".format(pipeline_time, 'msft'))\n",
    "predictor(df, 'msft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 11.808419704437256s for nflx\n",
      "aggregated error : 1154.4152604516844\n",
      "average error by prediction for nflx: -6.532616521740055\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pipeline('nflx-6m-weekly.csv', 'nflx')\n",
    "end = time.time()\n",
    "pipeline_time = end - start\n",
    "print(\"pipeline took {0}s for {1}\".format(pipeline_time, 'nflx'))\n",
    "predictor(df, 'nflx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 11.282693862915039s for amzn\n",
      "aggregated error : 3462.6780625021966\n",
      "average error by prediction for amzn: 4.462062612569146\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pipeline('amzn-6m-weekly.csv', 'amzn')\n",
    "end = time.time()\n",
    "pipeline_time = end - start\n",
    "print(\"pipeline took {0}s for {1}\".format(pipeline_time, 'amzn'))\n",
    "predictor(df, 'amzn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 10.789730072021484s for googl\n",
      "aggregated error : 16801.007336800598\n",
      "average error by prediction for googl: 26.4038610113792\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pipeline('googl-6m-weekly.csv', 'googl')\n",
    "end = time.time()\n",
    "pipeline_time = end - start\n",
    "print(\"pipeline took {0}s for {1}\".format(pipeline_time, 'googl'))\n",
    "predictor(df, 'googl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 12.934712171554565s for wmt\n",
      "aggregated error : 39.68606497767715\n",
      "average error by prediction for wmt: 0.2201927040481419\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = pipeline('wmt-6m-weekly.csv', 'wmt')\n",
    "end = time.time()\n",
    "pipeline_time = end - start\n",
    "print(\"pipeline took {0}s for {1}\".format(pipeline_time, 'wmt'))\n",
    "predictor(df, 'wmt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
